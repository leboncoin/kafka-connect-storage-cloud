/**
 * Autogenerated by Avro
 *
 * DO NOT EDIT DIRECTLY
 */
package io.confluent.connect.s3.file;

import org.apache.avro.generic.GenericArray;
import org.apache.avro.specific.SpecificData;
import org.apache.avro.util.Utf8;
import org.apache.avro.message.BinaryMessageEncoder;
import org.apache.avro.message.BinaryMessageDecoder;
import org.apache.avro.message.SchemaStore;

/** This event represents a fileEvent Message */
@org.apache.avro.specific.AvroGenerated
public class FileEvent extends org.apache.avro.specific.SpecificRecordBase implements org.apache.avro.specific.SpecificRecord {
    private static final long serialVersionUID = -4072574153031233223L;
    public static final org.apache.avro.Schema SCHEMA$ = new org.apache.avro.Schema.Parser().parse("{\"type\":\"record\",\"name\":\"FileEvent\",\"namespace\":\"io.confluent.connect.s3.file\",\"doc\":\"This event represents a fileEvent Message\",\"fields\":[{\"name\":\"topic_name\",\"type\":\"string\",\"doc\":\"The topic name of the record being written\"},{\"name\":\"s3_partition\",\"type\":\"string\",\"doc\":\"The s3 partition produced by the partitioner\"},{\"name\":\"file_path\",\"type\":\"string\",\"doc\":\"Current file path, including partition and file name\"},{\"name\":\"partition\",\"type\":\"int\",\"doc\":\"The kafka partition being recorded\"},{\"name\":\"base_record_timestamp\",\"type\":[\"null\",\"string\"],\"doc\":\"Time of the first record written in the file, in RFC 3339. Defined when partitioner is time based only.\"},{\"name\":\"current_timestamp\",\"type\":[\"null\",\"string\"],\"doc\":\"Time of the last record written in the file, in RFC 3339. Defined when partitioner is time based only.\"},{\"name\":\"record_count\",\"type\":\"int\",\"doc\":\"Number of records within the written file\"},{\"name\":\"event_datetime\",\"type\":\"string\",\"doc\":\"The time of the file event, in RFC 3339\"},{\"name\":\"database_name\",\"type\":[\"null\",\"string\"],\"doc\":\"The database name of the record being written\",\"default\":null},{\"name\":\"table_name\",\"type\":[\"null\",\"string\"],\"doc\":\"The table name of the record being written\",\"default\":null},{\"name\":\"cluster_name\",\"type\":[\"null\",\"string\"],\"doc\":\"Topic source cluster name\",\"default\":null}]}");
    public static org.apache.avro.Schema getClassSchema() { return SCHEMA$; }

    private static SpecificData MODEL$ = new SpecificData();

    private static final BinaryMessageEncoder<FileEvent> ENCODER =
            new BinaryMessageEncoder<FileEvent>(MODEL$, SCHEMA$);

    private static final BinaryMessageDecoder<FileEvent> DECODER =
            new BinaryMessageDecoder<FileEvent>(MODEL$, SCHEMA$);

    /**
     * Return the BinaryMessageEncoder instance used by this class.
     * @return the message encoder used by this class
     */
    public static BinaryMessageEncoder<FileEvent> getEncoder() {
        return ENCODER;
    }

    /**
     * Return the BinaryMessageDecoder instance used by this class.
     * @return the message decoder used by this class
     */
    public static BinaryMessageDecoder<FileEvent> getDecoder() {
        return DECODER;
    }

    /**
     * Create a new BinaryMessageDecoder instance for this class that uses the specified {@link SchemaStore}.
     * @param resolver a {@link SchemaStore} used to find schemas by fingerprint
     * @return a BinaryMessageDecoder instance for this class backed by the given SchemaStore
     */
    public static BinaryMessageDecoder<FileEvent> createDecoder(SchemaStore resolver) {
        return new BinaryMessageDecoder<FileEvent>(MODEL$, SCHEMA$, resolver);
    }

    /**
     * Serializes this FileEvent to a ByteBuffer.
     * @return a buffer holding the serialized data for this instance
     * @throws java.io.IOException if this instance could not be serialized
     */
    public java.nio.ByteBuffer toByteBuffer() throws java.io.IOException {
        return ENCODER.encode(this);
    }

    /**
     * Deserializes a FileEvent from a ByteBuffer.
     * @param b a byte buffer holding serialized data for an instance of this class
     * @return a FileEvent instance decoded from the given buffer
     * @throws java.io.IOException if the given bytes could not be deserialized into an instance of this class
     */
    public static FileEvent fromByteBuffer(
            java.nio.ByteBuffer b) throws java.io.IOException {
        return DECODER.decode(b);
    }

    /** The topic name of the record being written */
    @Deprecated public java.lang.CharSequence topic_name;
    /** The s3 partition produced by the partitioner */
    @Deprecated public java.lang.CharSequence s3_partition;
    /** Current file path, including partition and file name */
    @Deprecated public java.lang.CharSequence file_path;
    /** The kafka partition being recorded */
    @Deprecated public int partition;
    /** Time of the first record written in the file, in RFC 3339. Defined when partitioner is time based only. */
    @Deprecated public java.lang.CharSequence base_record_timestamp;
    /** Time of the last record written in the file, in RFC 3339. Defined when partitioner is time based only. */
    @Deprecated public java.lang.CharSequence current_timestamp;
    /** Number of records within the written file */
    @Deprecated public int record_count;
    /** The time of the file event, in RFC 3339 */
    @Deprecated public java.lang.CharSequence event_datetime;
    /** The database name of the record being written */
    @Deprecated public java.lang.CharSequence database_name;
    /** The table name of the record being written */
    @Deprecated public java.lang.CharSequence table_name;
    /** Topic source cluster name */
    @Deprecated public java.lang.CharSequence cluster_name;

    /**
     * Default constructor.  Note that this does not initialize fields
     * to their default values from the schema.  If that is desired then
     * one should use <code>newBuilder()</code>.
     */
    public FileEvent() {}

    /**
     * All-args constructor.
     * @param topic_name The topic name of the record being written
     * @param s3_partition The s3 partition produced by the partitioner
     * @param file_path Current file path, including partition and file name
     * @param partition The kafka partition being recorded
     * @param base_record_timestamp Time of the first record written in the file, in RFC 3339. Defined when partitioner is time based only.
     * @param current_timestamp Time of the last record written in the file, in RFC 3339. Defined when partitioner is time based only.
     * @param record_count Number of records within the written file
     * @param event_datetime The time of the file event, in RFC 3339
     * @param database_name The database name of the record being written
     * @param table_name The table name of the record being written
     * @param cluster_name Topic source cluster name
     */
    public FileEvent(java.lang.CharSequence topic_name, java.lang.CharSequence s3_partition, java.lang.CharSequence file_path, java.lang.Integer partition, java.lang.CharSequence base_record_timestamp, java.lang.CharSequence current_timestamp, java.lang.Integer record_count, java.lang.CharSequence event_datetime, java.lang.CharSequence database_name, java.lang.CharSequence table_name, java.lang.CharSequence cluster_name) {
        this.topic_name = topic_name;
        this.s3_partition = s3_partition;
        this.file_path = file_path;
        this.partition = partition;
        this.base_record_timestamp = base_record_timestamp;
        this.current_timestamp = current_timestamp;
        this.record_count = record_count;
        this.event_datetime = event_datetime;
        this.database_name = database_name;
        this.table_name = table_name;
        this.cluster_name = cluster_name;
    }

    public org.apache.avro.specific.SpecificData getSpecificData() { return MODEL$; }
    public org.apache.avro.Schema getSchema() { return SCHEMA$; }
    // Used by DatumWriter.  Applications should not call.
    public java.lang.Object get(int field$) {
        switch (field$) {
            case 0: return topic_name;
            case 1: return s3_partition;
            case 2: return file_path;
            case 3: return partition;
            case 4: return base_record_timestamp;
            case 5: return current_timestamp;
            case 6: return record_count;
            case 7: return event_datetime;
            case 8: return database_name;
            case 9: return table_name;
            case 10: return cluster_name;
            default: throw new org.apache.avro.AvroRuntimeException("Bad index");
        }
    }

    // Used by DatumReader.  Applications should not call.
    @SuppressWarnings(value="unchecked")
    public void put(int field$, java.lang.Object value$) {
        switch (field$) {
            case 0: topic_name = (java.lang.CharSequence)value$; break;
            case 1: s3_partition = (java.lang.CharSequence)value$; break;
            case 2: file_path = (java.lang.CharSequence)value$; break;
            case 3: partition = (java.lang.Integer)value$; break;
            case 4: base_record_timestamp = (java.lang.CharSequence)value$; break;
            case 5: current_timestamp = (java.lang.CharSequence)value$; break;
            case 6: record_count = (java.lang.Integer)value$; break;
            case 7: event_datetime = (java.lang.CharSequence)value$; break;
            case 8: database_name = (java.lang.CharSequence)value$; break;
            case 9: table_name = (java.lang.CharSequence)value$; break;
            case 10: cluster_name = (java.lang.CharSequence)value$; break;
            default: throw new org.apache.avro.AvroRuntimeException("Bad index");
        }
    }

    /**
     * Gets the value of the 'topic_name' field.
     * @return The topic name of the record being written
     */
    public java.lang.CharSequence getTopicName() {
        return topic_name;
    }


    /**
     * Sets the value of the 'topic_name' field.
     * The topic name of the record being written
     * @param value the value to set.
     */
    public void setTopicName(java.lang.CharSequence value) {
        this.topic_name = value;
    }

    /**
     * Gets the value of the 's3_partition' field.
     * @return The s3 partition produced by the partitioner
     */
    public java.lang.CharSequence getS3Partition() {
        return s3_partition;
    }


    /**
     * Sets the value of the 's3_partition' field.
     * The s3 partition produced by the partitioner
     * @param value the value to set.
     */
    public void setS3Partition(java.lang.CharSequence value) {
        this.s3_partition = value;
    }

    /**
     * Gets the value of the 'file_path' field.
     * @return Current file path, including partition and file name
     */
    public java.lang.CharSequence getFilePath() {
        return file_path;
    }


    /**
     * Sets the value of the 'file_path' field.
     * Current file path, including partition and file name
     * @param value the value to set.
     */
    public void setFilePath(java.lang.CharSequence value) {
        this.file_path = value;
    }

    /**
     * Gets the value of the 'partition' field.
     * @return The kafka partition being recorded
     */
    public int getPartition() {
        return partition;
    }


    /**
     * Sets the value of the 'partition' field.
     * The kafka partition being recorded
     * @param value the value to set.
     */
    public void setPartition(int value) {
        this.partition = value;
    }

    /**
     * Gets the value of the 'base_record_timestamp' field.
     * @return Time of the first record written in the file, in RFC 3339. Defined when partitioner is time based only.
     */
    public java.lang.CharSequence getBaseRecordTimestamp() {
        return base_record_timestamp;
    }


    /**
     * Sets the value of the 'base_record_timestamp' field.
     * Time of the first record written in the file, in RFC 3339. Defined when partitioner is time based only.
     * @param value the value to set.
     */
    public void setBaseRecordTimestamp(java.lang.CharSequence value) {
        this.base_record_timestamp = value;
    }

    /**
     * Gets the value of the 'current_timestamp' field.
     * @return Time of the last record written in the file, in RFC 3339. Defined when partitioner is time based only.
     */
    public java.lang.CharSequence getCurrentTimestamp() {
        return current_timestamp;
    }


    /**
     * Sets the value of the 'current_timestamp' field.
     * Time of the last record written in the file, in RFC 3339. Defined when partitioner is time based only.
     * @param value the value to set.
     */
    public void setCurrentTimestamp(java.lang.CharSequence value) {
        this.current_timestamp = value;
    }

    /**
     * Gets the value of the 'record_count' field.
     * @return Number of records within the written file
     */
    public int getRecordCount() {
        return record_count;
    }


    /**
     * Sets the value of the 'record_count' field.
     * Number of records within the written file
     * @param value the value to set.
     */
    public void setRecordCount(int value) {
        this.record_count = value;
    }

    /**
     * Gets the value of the 'event_datetime' field.
     * @return The time of the file event, in RFC 3339
     */
    public java.lang.CharSequence getEventDatetime() {
        return event_datetime;
    }


    /**
     * Sets the value of the 'event_datetime' field.
     * The time of the file event, in RFC 3339
     * @param value the value to set.
     */
    public void setEventDatetime(java.lang.CharSequence value) {
        this.event_datetime = value;
    }

    /**
     * Gets the value of the 'database_name' field.
     * @return The database name of the record being written
     */
    public java.lang.CharSequence getDatabaseName() {
        return database_name;
    }


    /**
     * Sets the value of the 'database_name' field.
     * The database name of the record being written
     * @param value the value to set.
     */
    public void setDatabaseName(java.lang.CharSequence value) {
        this.database_name = value;
    }

    /**
     * Gets the value of the 'table_name' field.
     * @return The table name of the record being written
     */
    public java.lang.CharSequence getTableName() {
        return table_name;
    }


    /**
     * Sets the value of the 'table_name' field.
     * The table name of the record being written
     * @param value the value to set.
     */
    public void setTableName(java.lang.CharSequence value) {
        this.table_name = value;
    }

    /**
     * Gets the value of the 'cluster_name' field.
     * @return Topic source cluster name
     */
    public java.lang.CharSequence getClusterName() {
        return cluster_name;
    }


    /**
     * Sets the value of the 'cluster_name' field.
     * Topic source cluster name
     * @param value the value to set.
     */
    public void setClusterName(java.lang.CharSequence value) {
        this.cluster_name = value;
    }

    /**
     * Creates a new FileEvent RecordBuilder.
     * @return A new FileEvent RecordBuilder
     */
    public static io.confluent.connect.s3.file.FileEvent.Builder newBuilder() {
        return new io.confluent.connect.s3.file.FileEvent.Builder();
    }

    /**
     * Creates a new FileEvent RecordBuilder by copying an existing Builder.
     * @param other The existing builder to copy.
     * @return A new FileEvent RecordBuilder
     */
    public static io.confluent.connect.s3.file.FileEvent.Builder newBuilder(io.confluent.connect.s3.file.FileEvent.Builder other) {
        if (other == null) {
            return new io.confluent.connect.s3.file.FileEvent.Builder();
        } else {
            return new io.confluent.connect.s3.file.FileEvent.Builder(other);
        }
    }

    /**
     * Creates a new FileEvent RecordBuilder by copying an existing FileEvent instance.
     * @param other The existing instance to copy.
     * @return A new FileEvent RecordBuilder
     */
    public static io.confluent.connect.s3.file.FileEvent.Builder newBuilder(io.confluent.connect.s3.file.FileEvent other) {
        if (other == null) {
            return new io.confluent.connect.s3.file.FileEvent.Builder();
        } else {
            return new io.confluent.connect.s3.file.FileEvent.Builder(other);
        }
    }

    /**
     * RecordBuilder for FileEvent instances.
     */
    @org.apache.avro.specific.AvroGenerated
    public static class Builder extends org.apache.avro.specific.SpecificRecordBuilderBase<FileEvent>
            implements org.apache.avro.data.RecordBuilder<FileEvent> {

        /** The topic name of the record being written */
        private java.lang.CharSequence topic_name;
        /** The s3 partition produced by the partitioner */
        private java.lang.CharSequence s3_partition;
        /** Current file path, including partition and file name */
        private java.lang.CharSequence file_path;
        /** The kafka partition being recorded */
        private int partition;
        /** Time of the first record written in the file, in RFC 3339. Defined when partitioner is time based only. */
        private java.lang.CharSequence base_record_timestamp;
        /** Time of the last record written in the file, in RFC 3339. Defined when partitioner is time based only. */
        private java.lang.CharSequence current_timestamp;
        /** Number of records within the written file */
        private int record_count;
        /** The time of the file event, in RFC 3339 */
        private java.lang.CharSequence event_datetime;
        /** The database name of the record being written */
        private java.lang.CharSequence database_name;
        /** The table name of the record being written */
        private java.lang.CharSequence table_name;
        /** Topic source cluster name */
        private java.lang.CharSequence cluster_name;

        /** Creates a new Builder */
        private Builder() {
            super(SCHEMA$);
        }

        /**
         * Creates a Builder by copying an existing Builder.
         * @param other The existing Builder to copy.
         */
        private Builder(io.confluent.connect.s3.file.FileEvent.Builder other) {
            super(other);
            if (isValidValue(fields()[0], other.topic_name)) {
                this.topic_name = data().deepCopy(fields()[0].schema(), other.topic_name);
                fieldSetFlags()[0] = other.fieldSetFlags()[0];
            }
            if (isValidValue(fields()[1], other.s3_partition)) {
                this.s3_partition = data().deepCopy(fields()[1].schema(), other.s3_partition);
                fieldSetFlags()[1] = other.fieldSetFlags()[1];
            }
            if (isValidValue(fields()[2], other.file_path)) {
                this.file_path = data().deepCopy(fields()[2].schema(), other.file_path);
                fieldSetFlags()[2] = other.fieldSetFlags()[2];
            }
            if (isValidValue(fields()[3], other.partition)) {
                this.partition = data().deepCopy(fields()[3].schema(), other.partition);
                fieldSetFlags()[3] = other.fieldSetFlags()[3];
            }
            if (isValidValue(fields()[4], other.base_record_timestamp)) {
                this.base_record_timestamp = data().deepCopy(fields()[4].schema(), other.base_record_timestamp);
                fieldSetFlags()[4] = other.fieldSetFlags()[4];
            }
            if (isValidValue(fields()[5], other.current_timestamp)) {
                this.current_timestamp = data().deepCopy(fields()[5].schema(), other.current_timestamp);
                fieldSetFlags()[5] = other.fieldSetFlags()[5];
            }
            if (isValidValue(fields()[6], other.record_count)) {
                this.record_count = data().deepCopy(fields()[6].schema(), other.record_count);
                fieldSetFlags()[6] = other.fieldSetFlags()[6];
            }
            if (isValidValue(fields()[7], other.event_datetime)) {
                this.event_datetime = data().deepCopy(fields()[7].schema(), other.event_datetime);
                fieldSetFlags()[7] = other.fieldSetFlags()[7];
            }
            if (isValidValue(fields()[8], other.database_name)) {
                this.database_name = data().deepCopy(fields()[8].schema(), other.database_name);
                fieldSetFlags()[8] = other.fieldSetFlags()[8];
            }
            if (isValidValue(fields()[9], other.table_name)) {
                this.table_name = data().deepCopy(fields()[9].schema(), other.table_name);
                fieldSetFlags()[9] = other.fieldSetFlags()[9];
            }
            if (isValidValue(fields()[10], other.cluster_name)) {
                this.cluster_name = data().deepCopy(fields()[10].schema(), other.cluster_name);
                fieldSetFlags()[10] = other.fieldSetFlags()[10];
            }
        }

        /**
         * Creates a Builder by copying an existing FileEvent instance
         * @param other The existing instance to copy.
         */
        private Builder(io.confluent.connect.s3.file.FileEvent other) {
            super(SCHEMA$);
            if (isValidValue(fields()[0], other.topic_name)) {
                this.topic_name = data().deepCopy(fields()[0].schema(), other.topic_name);
                fieldSetFlags()[0] = true;
            }
            if (isValidValue(fields()[1], other.s3_partition)) {
                this.s3_partition = data().deepCopy(fields()[1].schema(), other.s3_partition);
                fieldSetFlags()[1] = true;
            }
            if (isValidValue(fields()[2], other.file_path)) {
                this.file_path = data().deepCopy(fields()[2].schema(), other.file_path);
                fieldSetFlags()[2] = true;
            }
            if (isValidValue(fields()[3], other.partition)) {
                this.partition = data().deepCopy(fields()[3].schema(), other.partition);
                fieldSetFlags()[3] = true;
            }
            if (isValidValue(fields()[4], other.base_record_timestamp)) {
                this.base_record_timestamp = data().deepCopy(fields()[4].schema(), other.base_record_timestamp);
                fieldSetFlags()[4] = true;
            }
            if (isValidValue(fields()[5], other.current_timestamp)) {
                this.current_timestamp = data().deepCopy(fields()[5].schema(), other.current_timestamp);
                fieldSetFlags()[5] = true;
            }
            if (isValidValue(fields()[6], other.record_count)) {
                this.record_count = data().deepCopy(fields()[6].schema(), other.record_count);
                fieldSetFlags()[6] = true;
            }
            if (isValidValue(fields()[7], other.event_datetime)) {
                this.event_datetime = data().deepCopy(fields()[7].schema(), other.event_datetime);
                fieldSetFlags()[7] = true;
            }
            if (isValidValue(fields()[8], other.database_name)) {
                this.database_name = data().deepCopy(fields()[8].schema(), other.database_name);
                fieldSetFlags()[8] = true;
            }
            if (isValidValue(fields()[9], other.table_name)) {
                this.table_name = data().deepCopy(fields()[9].schema(), other.table_name);
                fieldSetFlags()[9] = true;
            }
            if (isValidValue(fields()[10], other.cluster_name)) {
                this.cluster_name = data().deepCopy(fields()[10].schema(), other.cluster_name);
                fieldSetFlags()[10] = true;
            }
        }

        /**
         * Gets the value of the 'topic_name' field.
         * The topic name of the record being written
         * @return The value.
         */
        public java.lang.CharSequence getTopicName() {
            return topic_name;
        }


        /**
         * Sets the value of the 'topic_name' field.
         * The topic name of the record being written
         * @param value The value of 'topic_name'.
         * @return This builder.
         */
        public io.confluent.connect.s3.file.FileEvent.Builder setTopicName(java.lang.CharSequence value) {
            validate(fields()[0], value);
            this.topic_name = value;
            fieldSetFlags()[0] = true;
            return this;
        }

        /**
         * Checks whether the 'topic_name' field has been set.
         * The topic name of the record being written
         * @return True if the 'topic_name' field has been set, false otherwise.
         */
        public boolean hasTopicName() {
            return fieldSetFlags()[0];
        }


        /**
         * Clears the value of the 'topic_name' field.
         * The topic name of the record being written
         * @return This builder.
         */
        public io.confluent.connect.s3.file.FileEvent.Builder clearTopicName() {
            topic_name = null;
            fieldSetFlags()[0] = false;
            return this;
        }

        /**
         * Gets the value of the 's3_partition' field.
         * The s3 partition produced by the partitioner
         * @return The value.
         */
        public java.lang.CharSequence getS3Partition() {
            return s3_partition;
        }


        /**
         * Sets the value of the 's3_partition' field.
         * The s3 partition produced by the partitioner
         * @param value The value of 's3_partition'.
         * @return This builder.
         */
        public io.confluent.connect.s3.file.FileEvent.Builder setS3Partition(java.lang.CharSequence value) {
            validate(fields()[1], value);
            this.s3_partition = value;
            fieldSetFlags()[1] = true;
            return this;
        }

        /**
         * Checks whether the 's3_partition' field has been set.
         * The s3 partition produced by the partitioner
         * @return True if the 's3_partition' field has been set, false otherwise.
         */
        public boolean hasS3Partition() {
            return fieldSetFlags()[1];
        }


        /**
         * Clears the value of the 's3_partition' field.
         * The s3 partition produced by the partitioner
         * @return This builder.
         */
        public io.confluent.connect.s3.file.FileEvent.Builder clearS3Partition() {
            s3_partition = null;
            fieldSetFlags()[1] = false;
            return this;
        }

        /**
         * Gets the value of the 'file_path' field.
         * Current file path, including partition and file name
         * @return The value.
         */
        public java.lang.CharSequence getFilePath() {
            return file_path;
        }


        /**
         * Sets the value of the 'file_path' field.
         * Current file path, including partition and file name
         * @param value The value of 'file_path'.
         * @return This builder.
         */
        public io.confluent.connect.s3.file.FileEvent.Builder setFilePath(java.lang.CharSequence value) {
            validate(fields()[2], value);
            this.file_path = value;
            fieldSetFlags()[2] = true;
            return this;
        }

        /**
         * Checks whether the 'file_path' field has been set.
         * Current file path, including partition and file name
         * @return True if the 'file_path' field has been set, false otherwise.
         */
        public boolean hasFilePath() {
            return fieldSetFlags()[2];
        }


        /**
         * Clears the value of the 'file_path' field.
         * Current file path, including partition and file name
         * @return This builder.
         */
        public io.confluent.connect.s3.file.FileEvent.Builder clearFilePath() {
            file_path = null;
            fieldSetFlags()[2] = false;
            return this;
        }

        /**
         * Gets the value of the 'partition' field.
         * The kafka partition being recorded
         * @return The value.
         */
        public int getPartition() {
            return partition;
        }


        /**
         * Sets the value of the 'partition' field.
         * The kafka partition being recorded
         * @param value The value of 'partition'.
         * @return This builder.
         */
        public io.confluent.connect.s3.file.FileEvent.Builder setPartition(int value) {
            validate(fields()[3], value);
            this.partition = value;
            fieldSetFlags()[3] = true;
            return this;
        }

        /**
         * Checks whether the 'partition' field has been set.
         * The kafka partition being recorded
         * @return True if the 'partition' field has been set, false otherwise.
         */
        public boolean hasPartition() {
            return fieldSetFlags()[3];
        }


        /**
         * Clears the value of the 'partition' field.
         * The kafka partition being recorded
         * @return This builder.
         */
        public io.confluent.connect.s3.file.FileEvent.Builder clearPartition() {
            fieldSetFlags()[3] = false;
            return this;
        }

        /**
         * Gets the value of the 'base_record_timestamp' field.
         * Time of the first record written in the file, in RFC 3339. Defined when partitioner is time based only.
         * @return The value.
         */
        public java.lang.CharSequence getBaseRecordTimestamp() {
            return base_record_timestamp;
        }


        /**
         * Sets the value of the 'base_record_timestamp' field.
         * Time of the first record written in the file, in RFC 3339. Defined when partitioner is time based only.
         * @param value The value of 'base_record_timestamp'.
         * @return This builder.
         */
        public io.confluent.connect.s3.file.FileEvent.Builder setBaseRecordTimestamp(java.lang.CharSequence value) {
            validate(fields()[4], value);
            this.base_record_timestamp = value;
            fieldSetFlags()[4] = true;
            return this;
        }

        /**
         * Checks whether the 'base_record_timestamp' field has been set.
         * Time of the first record written in the file, in RFC 3339. Defined when partitioner is time based only.
         * @return True if the 'base_record_timestamp' field has been set, false otherwise.
         */
        public boolean hasBaseRecordTimestamp() {
            return fieldSetFlags()[4];
        }


        /**
         * Clears the value of the 'base_record_timestamp' field.
         * Time of the first record written in the file, in RFC 3339. Defined when partitioner is time based only.
         * @return This builder.
         */
        public io.confluent.connect.s3.file.FileEvent.Builder clearBaseRecordTimestamp() {
            base_record_timestamp = null;
            fieldSetFlags()[4] = false;
            return this;
        }

        /**
         * Gets the value of the 'current_timestamp' field.
         * Time of the last record written in the file, in RFC 3339. Defined when partitioner is time based only.
         * @return The value.
         */
        public java.lang.CharSequence getCurrentTimestamp() {
            return current_timestamp;
        }


        /**
         * Sets the value of the 'current_timestamp' field.
         * Time of the last record written in the file, in RFC 3339. Defined when partitioner is time based only.
         * @param value The value of 'current_timestamp'.
         * @return This builder.
         */
        public io.confluent.connect.s3.file.FileEvent.Builder setCurrentTimestamp(java.lang.CharSequence value) {
            validate(fields()[5], value);
            this.current_timestamp = value;
            fieldSetFlags()[5] = true;
            return this;
        }

        /**
         * Checks whether the 'current_timestamp' field has been set.
         * Time of the last record written in the file, in RFC 3339. Defined when partitioner is time based only.
         * @return True if the 'current_timestamp' field has been set, false otherwise.
         */
        public boolean hasCurrentTimestamp() {
            return fieldSetFlags()[5];
        }


        /**
         * Clears the value of the 'current_timestamp' field.
         * Time of the last record written in the file, in RFC 3339. Defined when partitioner is time based only.
         * @return This builder.
         */
        public io.confluent.connect.s3.file.FileEvent.Builder clearCurrentTimestamp() {
            current_timestamp = null;
            fieldSetFlags()[5] = false;
            return this;
        }

        /**
         * Gets the value of the 'record_count' field.
         * Number of records within the written file
         * @return The value.
         */
        public int getRecordCount() {
            return record_count;
        }


        /**
         * Sets the value of the 'record_count' field.
         * Number of records within the written file
         * @param value The value of 'record_count'.
         * @return This builder.
         */
        public io.confluent.connect.s3.file.FileEvent.Builder setRecordCount(int value) {
            validate(fields()[6], value);
            this.record_count = value;
            fieldSetFlags()[6] = true;
            return this;
        }

        /**
         * Checks whether the 'record_count' field has been set.
         * Number of records within the written file
         * @return True if the 'record_count' field has been set, false otherwise.
         */
        public boolean hasRecordCount() {
            return fieldSetFlags()[6];
        }


        /**
         * Clears the value of the 'record_count' field.
         * Number of records within the written file
         * @return This builder.
         */
        public io.confluent.connect.s3.file.FileEvent.Builder clearRecordCount() {
            fieldSetFlags()[6] = false;
            return this;
        }

        /**
         * Gets the value of the 'event_datetime' field.
         * The time of the file event, in RFC 3339
         * @return The value.
         */
        public java.lang.CharSequence getEventDatetime() {
            return event_datetime;
        }


        /**
         * Sets the value of the 'event_datetime' field.
         * The time of the file event, in RFC 3339
         * @param value The value of 'event_datetime'.
         * @return This builder.
         */
        public io.confluent.connect.s3.file.FileEvent.Builder setEventDatetime(java.lang.CharSequence value) {
            validate(fields()[7], value);
            this.event_datetime = value;
            fieldSetFlags()[7] = true;
            return this;
        }

        /**
         * Checks whether the 'event_datetime' field has been set.
         * The time of the file event, in RFC 3339
         * @return True if the 'event_datetime' field has been set, false otherwise.
         */
        public boolean hasEventDatetime() {
            return fieldSetFlags()[7];
        }


        /**
         * Clears the value of the 'event_datetime' field.
         * The time of the file event, in RFC 3339
         * @return This builder.
         */
        public io.confluent.connect.s3.file.FileEvent.Builder clearEventDatetime() {
            event_datetime = null;
            fieldSetFlags()[7] = false;
            return this;
        }

        /**
         * Gets the value of the 'database_name' field.
         * The database name of the record being written
         * @return The value.
         */
        public java.lang.CharSequence getDatabaseName() {
            return database_name;
        }


        /**
         * Sets the value of the 'database_name' field.
         * The database name of the record being written
         * @param value The value of 'database_name'.
         * @return This builder.
         */
        public io.confluent.connect.s3.file.FileEvent.Builder setDatabaseName(java.lang.CharSequence value) {
            validate(fields()[8], value);
            this.database_name = value;
            fieldSetFlags()[8] = true;
            return this;
        }

        /**
         * Checks whether the 'database_name' field has been set.
         * The database name of the record being written
         * @return True if the 'database_name' field has been set, false otherwise.
         */
        public boolean hasDatabaseName() {
            return fieldSetFlags()[8];
        }


        /**
         * Clears the value of the 'database_name' field.
         * The database name of the record being written
         * @return This builder.
         */
        public io.confluent.connect.s3.file.FileEvent.Builder clearDatabaseName() {
            database_name = null;
            fieldSetFlags()[8] = false;
            return this;
        }

        /**
         * Gets the value of the 'table_name' field.
         * The table name of the record being written
         * @return The value.
         */
        public java.lang.CharSequence getTableName() {
            return table_name;
        }


        /**
         * Sets the value of the 'table_name' field.
         * The table name of the record being written
         * @param value The value of 'table_name'.
         * @return This builder.
         */
        public io.confluent.connect.s3.file.FileEvent.Builder setTableName(java.lang.CharSequence value) {
            validate(fields()[9], value);
            this.table_name = value;
            fieldSetFlags()[9] = true;
            return this;
        }

        /**
         * Checks whether the 'table_name' field has been set.
         * The table name of the record being written
         * @return True if the 'table_name' field has been set, false otherwise.
         */
        public boolean hasTableName() {
            return fieldSetFlags()[9];
        }


        /**
         * Clears the value of the 'table_name' field.
         * The table name of the record being written
         * @return This builder.
         */
        public io.confluent.connect.s3.file.FileEvent.Builder clearTableName() {
            table_name = null;
            fieldSetFlags()[9] = false;
            return this;
        }

        /**
         * Gets the value of the 'cluster_name' field.
         * Topic source cluster name
         * @return The value.
         */
        public java.lang.CharSequence getClusterName() {
            return cluster_name;
        }


        /**
         * Sets the value of the 'cluster_name' field.
         * Topic source cluster name
         * @param value The value of 'cluster_name'.
         * @return This builder.
         */
        public io.confluent.connect.s3.file.FileEvent.Builder setClusterName(java.lang.CharSequence value) {
            validate(fields()[10], value);
            this.cluster_name = value;
            fieldSetFlags()[10] = true;
            return this;
        }

        /**
         * Checks whether the 'cluster_name' field has been set.
         * Topic source cluster name
         * @return True if the 'cluster_name' field has been set, false otherwise.
         */
        public boolean hasClusterName() {
            return fieldSetFlags()[10];
        }


        /**
         * Clears the value of the 'cluster_name' field.
         * Topic source cluster name
         * @return This builder.
         */
        public io.confluent.connect.s3.file.FileEvent.Builder clearClusterName() {
            cluster_name = null;
            fieldSetFlags()[10] = false;
            return this;
        }

        @Override
        @SuppressWarnings("unchecked")
        public FileEvent build() {
            try {
                FileEvent record = new FileEvent();
                record.topic_name = fieldSetFlags()[0] ? this.topic_name : (java.lang.CharSequence) defaultValue(fields()[0]);
                record.s3_partition = fieldSetFlags()[1] ? this.s3_partition : (java.lang.CharSequence) defaultValue(fields()[1]);
                record.file_path = fieldSetFlags()[2] ? this.file_path : (java.lang.CharSequence) defaultValue(fields()[2]);
                record.partition = fieldSetFlags()[3] ? this.partition : (java.lang.Integer) defaultValue(fields()[3]);
                record.base_record_timestamp = fieldSetFlags()[4] ? this.base_record_timestamp : (java.lang.CharSequence) defaultValue(fields()[4]);
                record.current_timestamp = fieldSetFlags()[5] ? this.current_timestamp : (java.lang.CharSequence) defaultValue(fields()[5]);
                record.record_count = fieldSetFlags()[6] ? this.record_count : (java.lang.Integer) defaultValue(fields()[6]);
                record.event_datetime = fieldSetFlags()[7] ? this.event_datetime : (java.lang.CharSequence) defaultValue(fields()[7]);
                record.database_name = fieldSetFlags()[8] ? this.database_name : (java.lang.CharSequence) defaultValue(fields()[8]);
                record.table_name = fieldSetFlags()[9] ? this.table_name : (java.lang.CharSequence) defaultValue(fields()[9]);
                record.cluster_name = fieldSetFlags()[10] ? this.cluster_name : (java.lang.CharSequence) defaultValue(fields()[10]);
                return record;
            } catch (org.apache.avro.AvroMissingFieldException e) {
                throw e;
            } catch (java.lang.Exception e) {
                throw new org.apache.avro.AvroRuntimeException(e);
            }
        }
    }

    @SuppressWarnings("unchecked")
    private static final org.apache.avro.io.DatumWriter<FileEvent>
            WRITER$ = (org.apache.avro.io.DatumWriter<FileEvent>)MODEL$.createDatumWriter(SCHEMA$);

    @Override public void writeExternal(java.io.ObjectOutput out)
            throws java.io.IOException {
        WRITER$.write(this, SpecificData.getEncoder(out));
    }

    @SuppressWarnings("unchecked")
    private static final org.apache.avro.io.DatumReader<FileEvent>
            READER$ = (org.apache.avro.io.DatumReader<FileEvent>)MODEL$.createDatumReader(SCHEMA$);

    @Override public void readExternal(java.io.ObjectInput in)
            throws java.io.IOException {
        READER$.read(this, SpecificData.getDecoder(in));
    }

    @Override protected boolean hasCustomCoders() { return true; }

    @Override public void customEncode(org.apache.avro.io.Encoder out)
            throws java.io.IOException
    {
        out.writeString(this.topic_name);

        out.writeString(this.s3_partition);

        out.writeString(this.file_path);

        out.writeInt(this.partition);

        if (this.base_record_timestamp == null) {
            out.writeIndex(0);
            out.writeNull();
        } else {
            out.writeIndex(1);
            out.writeString(this.base_record_timestamp);
        }

        if (this.current_timestamp == null) {
            out.writeIndex(0);
            out.writeNull();
        } else {
            out.writeIndex(1);
            out.writeString(this.current_timestamp);
        }

        out.writeInt(this.record_count);

        out.writeString(this.event_datetime);

        if (this.database_name == null) {
            out.writeIndex(0);
            out.writeNull();
        } else {
            out.writeIndex(1);
            out.writeString(this.database_name);
        }

        if (this.table_name == null) {
            out.writeIndex(0);
            out.writeNull();
        } else {
            out.writeIndex(1);
            out.writeString(this.table_name);
        }

        if (this.cluster_name == null) {
            out.writeIndex(0);
            out.writeNull();
        } else {
            out.writeIndex(1);
            out.writeString(this.cluster_name);
        }

    }

    @Override public void customDecode(org.apache.avro.io.ResolvingDecoder in)
            throws java.io.IOException
    {
        org.apache.avro.Schema.Field[] fieldOrder = in.readFieldOrderIfDiff();
        if (fieldOrder == null) {
            this.topic_name = in.readString(this.topic_name instanceof Utf8 ? (Utf8)this.topic_name : null);

            this.s3_partition = in.readString(this.s3_partition instanceof Utf8 ? (Utf8)this.s3_partition : null);

            this.file_path = in.readString(this.file_path instanceof Utf8 ? (Utf8)this.file_path : null);

            this.partition = in.readInt();

            if (in.readIndex() != 1) {
                in.readNull();
                this.base_record_timestamp = null;
            } else {
                this.base_record_timestamp = in.readString(this.base_record_timestamp instanceof Utf8 ? (Utf8)this.base_record_timestamp : null);
            }

            if (in.readIndex() != 1) {
                in.readNull();
                this.current_timestamp = null;
            } else {
                this.current_timestamp = in.readString(this.current_timestamp instanceof Utf8 ? (Utf8)this.current_timestamp : null);
            }

            this.record_count = in.readInt();

            this.event_datetime = in.readString(this.event_datetime instanceof Utf8 ? (Utf8)this.event_datetime : null);

            if (in.readIndex() != 1) {
                in.readNull();
                this.database_name = null;
            } else {
                this.database_name = in.readString(this.database_name instanceof Utf8 ? (Utf8)this.database_name : null);
            }

            if (in.readIndex() != 1) {
                in.readNull();
                this.table_name = null;
            } else {
                this.table_name = in.readString(this.table_name instanceof Utf8 ? (Utf8)this.table_name : null);
            }

            if (in.readIndex() != 1) {
                in.readNull();
                this.cluster_name = null;
            } else {
                this.cluster_name = in.readString(this.cluster_name instanceof Utf8 ? (Utf8)this.cluster_name : null);
            }

        } else {
            for (int i = 0; i < 11; i++) {
                switch (fieldOrder[i].pos()) {
                    case 0:
                        this.topic_name = in.readString(this.topic_name instanceof Utf8 ? (Utf8)this.topic_name : null);
                        break;

                    case 1:
                        this.s3_partition = in.readString(this.s3_partition instanceof Utf8 ? (Utf8)this.s3_partition : null);
                        break;

                    case 2:
                        this.file_path = in.readString(this.file_path instanceof Utf8 ? (Utf8)this.file_path : null);
                        break;

                    case 3:
                        this.partition = in.readInt();
                        break;

                    case 4:
                        if (in.readIndex() != 1) {
                            in.readNull();
                            this.base_record_timestamp = null;
                        } else {
                            this.base_record_timestamp = in.readString(this.base_record_timestamp instanceof Utf8 ? (Utf8)this.base_record_timestamp : null);
                        }
                        break;

                    case 5:
                        if (in.readIndex() != 1) {
                            in.readNull();
                            this.current_timestamp = null;
                        } else {
                            this.current_timestamp = in.readString(this.current_timestamp instanceof Utf8 ? (Utf8)this.current_timestamp : null);
                        }
                        break;

                    case 6:
                        this.record_count = in.readInt();
                        break;

                    case 7:
                        this.event_datetime = in.readString(this.event_datetime instanceof Utf8 ? (Utf8)this.event_datetime : null);
                        break;

                    case 8:
                        if (in.readIndex() != 1) {
                            in.readNull();
                            this.database_name = null;
                        } else {
                            this.database_name = in.readString(this.database_name instanceof Utf8 ? (Utf8)this.database_name : null);
                        }
                        break;

                    case 9:
                        if (in.readIndex() != 1) {
                            in.readNull();
                            this.table_name = null;
                        } else {
                            this.table_name = in.readString(this.table_name instanceof Utf8 ? (Utf8)this.table_name : null);
                        }
                        break;

                    case 10:
                        if (in.readIndex() != 1) {
                            in.readNull();
                            this.cluster_name = null;
                        } else {
                            this.cluster_name = in.readString(this.cluster_name instanceof Utf8 ? (Utf8)this.cluster_name : null);
                        }
                        break;

                    default:
                        throw new java.io.IOException("Corrupt ResolvingDecoder.");
                }
            }
        }
    }
}










